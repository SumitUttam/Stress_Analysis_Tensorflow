{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2DeYSMNgbPNPpN5QA3knE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLGP-I_pfgng"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model, Sequential, load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yiGMarSAxJj",
        "outputId": "e550b442-dd26-41d2-bc0f-3952823ed2ad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6yeaDrSA5_d"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/StressAnalysis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLjZCkNIBqXU",
        "outputId": "0e1b7709-d237-48d5-c83e-474cb94c4c01"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import string\n",
        "import re\n",
        "\n",
        "vocab_file = 'vocab.txt'\n",
        "class_names = ['normal', \"depressed\"]\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped = tf.strings.regex_replace(lowercase, \"\\n\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "        stripped, \"[%s]\" % re.escape(string.punctuation), \"\"\n",
        "    )\n",
        "\n",
        "# Model constants.\n",
        "max_features = 20000\n",
        "embedding_dim = 128\n",
        "sequence_length = 1000\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "print (\"attempting to recover previous vocabulary...\")\n",
        "f = open(vocab_file, 'r')\n",
        "vocab = f.read().split('\\n')\n",
        "vocab = vocab[1:]\n",
        "vectorize_layer.set_vocabulary(vocab, df_data=None, oov_df_value=None)\n",
        "print ('previous vocabulary loaded')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "attempting to recover previous vocabulary...\n",
            "previous vocabulary loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPCN5bvpBP8_",
        "outputId": "07bc2e4e-6dca-42c5-b460-831747065168"
      },
      "source": [
        "model = load_model('binary_model_LSTM.h5')\n",
        "model.summary()\n",
        "model.compile()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 256)               263168    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,864,385\n",
            "Trainable params: 2,864,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngOrpN0aBkVf"
      },
      "source": [
        "# A string input\n",
        "inputs = tf.keras.Input(shape=(1,), dtype=\"string\")\n",
        "# Turn strings into vocab indices\n",
        "indices = vectorize_layer(inputs)\n",
        "# Turn vocab indices into predictions\n",
        "outputs = model(indices)\n",
        "\n",
        "# Our end to end model\n",
        "end_to_end_model = tf.keras.Model(inputs, outputs)\n",
        "end_to_end_model.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxbk2IQpC3Sz"
      },
      "source": [
        "#predict function\n",
        "def predict_post(string):\n",
        "    pred = end_to_end_model.predict(string)\n",
        "    print(pred)\n",
        "    pred = int(np.round(pred[0][0]))\n",
        "    print (pred)\n",
        "    print (class_names[pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb0tbTyWDGA8",
        "outputId": "80edb8a6-b827-469a-af9a-0e0ff1c34a0b"
      },
      "source": [
        "text = ['I am tired \\n tired of waiting, I am not waiting anymore I want it to be over it hurts me and my family.']\n",
        "predict_post(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.4467659e-07]]\n",
            "0\n",
            "normal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlhPNM6KDKOS"
      },
      "source": [
        "text = input()\n",
        "predict_post([text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCjaMJfeDqNA"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}